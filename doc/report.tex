\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{a4wide}
\usepackage{graphicx}
\usepackage{float}
\usepackage{url}
\usepackage{todonotes}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{parskip}

\setlength\parindent{0pt}

\title{TSBK07 - Project}
\author{Hans-Filip Elo (hanel742), Lage Ragnarsson (lagra033) and Isak Wiberg (isawi527)}
\date{May 2016}

\begin{document}

\maketitle
\newpage
\section{Introduction}
% Describe the problem, basically the specification you started from. What features were mandatory and optional?

We've created a 3D graphics engine that we call ''Emerald'' from specification created before the start of the project\footnote{\url{https://github.com/lragnarsson/Emerald-Engine/blob/master/doc/project_specification.md}}.

The project specification were divided into two parts, one ''will-do'' part and one ''might-do'' part.

The reader of this document is expected to have some knowledge of the OpenGL rendering pipeline\footnote{\url{OpenGL rendering pipeline, https://www.opengl.org/wiki/Rendering_Pipeline_Overview}}

\subsection{Will-do features}

\begin{itemize}
    \item Deferred Shading
    \item Screen Space Ambient Occlusion (SSAO)
    \item User Controlled Movement of the 3D Camera
    \item Multi-Mesh Model Loading
\end{itemize}

User controlled movement of the 3D-camera is quite self-explanatory, but for the others a short description follows.

\paragraph{Deferred Shading}
Deferred shading is a technique where you split the geometry and shading stages of the rendering pipeline even further. The geometry stage writes to four buffers, with the same ammount of columns as the number of pixels on screen, instead of outputing data for each vertex to a fragment shader. Only light and depth components that's supposed to be rendered to the screen are then left for the shading stage. The buffers contain the following information for each pixel:

\begin{itemize}
    \item Diffuse - \textit{Contains diffuse light component}
    \item Depth - \textit{Contains depth information for each pixel}
    \item Normal - \textit{Contains normal values in each pixel}
    \item Albedo - \textit{Contains texture data for each pixel}
\end{itemize}

In the lighting stage a fragment shader then reads from these buffers. Since the buffers only contain values for geometry that's projected to the screen - the renderer only calculates shading for pixels actually drawn.

\paragraph{SSAO}

SSAO is... // TODO

\paragraph{Multi-Mesh Model Loading}

This means that the Engine is able to load complex models consisting of more than one mesh.

\section{Background information}

Any information about the kind of problem you solved that is needed to follow the rest of the report.

\section{Implementation}

The engine is written in C++ and GLSL. The engine uses the libraries Simple Directmedia Layer version 2 (SDL2)\footnote{\url{https://www.libsdl.org}}, The OpenGL Extension Wrangler Library (GLEW)\footnote{\url{http://glew.sourceforge.net/}}, Open Asset Import Library (Assimp)\footnote{\url{http://www.assimp.org/}} and Anttweakbar\footnote{\url{http://anttweakbar.sourceforge.net/}} in order to get some abstractions and be platform independent.

The engine currently consists of six main modules in the form of C++ classes, with some glue code to get them running, and 11 shader pairs. The components of the C++ program are:

\begin{itemize}
    \item Animation Path
    \item Camera
    \item Light
    \item Loader
    \item Model
    \item Renderer
\end{itemize}

\subsection{Loader}

The Loader reads a scene file writte n in the Emerald scene file format\footnote{\url{https://github.com/lragnarsson/Emerald-Engine/blob/master/doc/project_specification.md}} into the graphics engine. Having a separate file format for specifying scenes greatly reduces code clutter, since writing scene creation in code is repetetive and looks bloated.

\subsection{Camera}

The camera holds information of the camera position, as well as witch animation path to follow (if any).

\subsection{Animation Path}

An animation path holds a series of coordinates in 3D-space (at least four). The coordinates are then used by the Animation Path to calculate Catmull-Rom splines \footnote{Ingemar Ragnemalm, fetched May 2016, \url{http://www.computer-graphics.se/TSBK07-files/pdf16/11b.pdf}} which is used for smooth movement of objects.

\subsection{Renderer}

This module renders all objects in the world using references to GPU-data found in models, lights and the Camera. All logic in the rendering pipeline is controlled from this module.

\subsection{Light}

A Light is a container for light sources. It can upload itself to the GPU when changed in order for image to update on the next render cycle.

\subsection{Model}

A model is a container for everything that is needed in order to render the model to screen. The model class includes the loader which loads a model from file, and then uploads itself and its meshes to the GPU, leaving only references to the data available to the Renderer.

A model can have lights as well as animation paths attached to it, in order for it to shine as well as move.

\section{Problems}

// TODO: Write about how awesome Git is.

Git is awesome, everyone in project is awesome

\section{Conclusions}

// TODO: No idea...

How did it come out? How could it have been done better?

\end{document}
